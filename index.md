# Data description
Gamma-ray bursts (GRBs) and blazars, two of the most energetic phenomena in our universe, are thought to be powered by central engines spewing out jets of plasma at close to the speed of light. These jets contain so much energy that in a single event they can briefly outshine their host galaxy. Missions such as NASA’s Fermi Gamma-ray Space Telescope have produced a wealth of observational data over the last three decades, however many details surrounding these phenomena, including the jet structure and the role radiation-matter interactions play in jet evolution, remain unknown. How does the energy contained in jets translate to the radiation (i.e., light) we observe? How can we improve the accuracy of the physics represented in computational models? Can simulation results, in the form of light curves and spectra, be reliably compared to existing observational data? These are the principle questions I will be investigating as part of the Computational Astrophysics group here at OSU, where as part of my thesis work I will develop a 3Dl special relativity hydrodynamic (SRHD) code that incorporates radiation and magnetic effects to more accurately capture jet dynamics. 
	
 As a computational project, data will be key to the work. Data regarding known astrophysical jet sources, which includes data such as mass, angular momentum, and metallicity, from different central engines will be used as the simulated progenitor (our initial setup). Such data will be captured from online astronomical catalogues. As a simulated output, light curves (intensity, or total power output over time) and spectra (counts from a source as a function of energy) are the goal as they can be directly compared to observational data. To achieve these numerical results, a 3D SRHD code will be developed using a combination of C++ and Python will be developed, as no public code is currently available. Due to the compute intensive nature of these simulations, the code will be developed in such a way that leverages high-performance computing architectures. It is expected that this project will ultimately produce on the order of hundreds of GB of data. 


# Roles and responsibilities
As a computational theorist, the responsibility for data management will fall largely on me as the primary researcher, and to a lesser extent on my advisor, who will provide basic guidance with such things as theoretical and numerical frameworks, common practices, and where to start my literature search. I will be responsible, ultimately, for developing code, managing data, conducting the appropriate data analysis, etc. My advisor, to some extent, will be co-responsible for such things as quality control-- both of the data as well as analysis techniques. Since my research question does not involve the use of human subjects, the data produced by this research project will not be sensitive or confidential; nor is my research under some sort of non-disclosure agreement that would prevent the dissemination of data. However, funding agencies, namely NSF, will require a Data Management Plan during the proposal stage, which will include plans to make data available (talking with my advisor, it appears whether it’s made freely available or made available by request seems to be to the discretion of the researcher).    
# Data standards and metadata

# Storage and security

# Access and data sharing

# Archiving and preservation

Repository with source code [here](https://github.com/clarallebot/GRAD521_DMPtemplate)
